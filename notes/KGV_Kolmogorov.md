# Kolmogorov–Smirnov Criterion (KS)

## اطلاعات کلی
- **منبع اصلی:** A Combined Nonparametric Approach to Feature Selection and Binary Decision Tree Design – E.M. Rounds (1980)  
- **مجله:** Pattern Recognition, Vol. 12, pp. 313–317  
- **انگیزه:** ارائه روشی غیرپارامتری برای انتخاب ویژگی و تقسیم درخت تصمیم  
- **مزیت کلیدی:** ترکیب انتخاب ویژگی با ساخت درخت و عدم نیاز به فرض توزیع  

## هدف و کاربرد
معیار KS برای مسائل طبقه‌بندی باینری طراحی شده است تا در هر گره، بهترین ویژگی با بیشترین فاصله توزیع تجمعی دو کلاس انتخاب شود. این روش:
1. بدون فرض توزیع  
2. مقاوم در برابر چگالی‌های پرت  
3. انتخاب ویژگی و آستانه بهینه را همزمان انجام می‌دهد  

## فرمول ریاضی
برای هر ویژگی \(X\) و آستانه \(t\):
\[
D = \max_x \bigl|\hat F_0(x) - \hat F_1(x)\bigr|
\]
که در آن \(\hat F_i(x)\) تابع توزیع تجمعی تجربی کلاس \(i\) است.

## الگوریتم کلی
1. برای هر ویژگی \(X_j\):  
   a. محاسبه \(\hat F_0(x)\) و \(\hat F_1(x)\)  
   b. یافتن \(D_j\) و آستانه \(t_j\) که \(D_j\) را به حداکثر می‌رساند  
2. انتخاب ویژگی با بیشترین \(D_j\)  
3. تقسیم داده‌ها بر اساس آستانه \(t_j\)  
4. تکرار در گره‌های فرزند تا معیار توقف  

## مثال کاربردی
برای دو کلاس با نمونه‌های زیر:

| \(x\) | کلاس 0 | کلاس 1 |
|-------|--------|--------|
| 2.1   | ●      |        |
| 3.5   | ●
def ks_split(x, y):
# مرتب‌سازی داده بر حسب x
# محاسبه CDF دو کلاس
# یافتن D و t بهینه
# بازگشت D, t
```
## منابع
- Rounds, E.M. (1980). A Combined Nonparametric Approach … Pattern Recognition  
- سایر مراجع آزمون K–S و کاربرد در یادگیری ماشین  
