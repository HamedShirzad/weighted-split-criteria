import numpy as np
#from custom_tree_classifier.models.decision_tree import CustomDecisionTreeClassifier
from custom_tree_classifier.metrics.metric_base import MetricBase
# Ø§Ø² Ø¢Ù†Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ø¯ÛŒÚ¯Ø± Ø§Ø² Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¢Ù† Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯ ÛŒØ§ Ú©Ø§Ù…Ù†Øª Ú©Ø±Ø¯
# from utils.voting_split_manager import FNWeightedSplitManager

# Import Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
#from criteria.gini import gini_criterion
from criteria.qg import gain_ratio_criterion
from criteria.twoing import twoing_criterion
from criteria.ng import normalized_gain_criterion
from criteria.mch import multi_class_hellinger
from criteria.marsh import marsh_criterion
from criteria.gs import g_statistic_criterion
from criteria.dkm import dkm_criterion
from criteria.cs import chi_squared_criterion
from criteria.bhy import bhattacharyya_criterion
from criteria.ks import kolmogorov_smirnov_criterion

# ================================================================
# ğŸ”¥ Ú©Ù„Ø§Ø³ Û±: SingleCriterionMetric (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ğŸ”¥
# Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø±Ø§ Ø¨Ù‡ Ø®ÙˆØ¯ ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø± Ù…ÛŒâ€ŒØ³Ù¾Ø§Ø±Ø¯.
# ================================================================
class SingleCriterionMetric(MetricBase):
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ú©Ù…Ú©ÛŒ Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ú©Ù‡ ÛŒÚ© ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø± Ú©ÛŒÙÛŒØª ØªÙ‚Ø³ÛŒÙ… (Split Quality Function)
    Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ÛŒ Ú©Ù‡ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ CustomDecisionTreeClassifier Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±Ø¯ØŒ Ø¨Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    def __init__(self, name, func):
        super().__init__()
        self.name = name
        self.func = func  # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ (y_left, y_right) Ø±Ø§ Ø¨Ù¾Ø°ÛŒØ±Ø¯

    def compute_metric(self, metric_data: np.ndarray) -> float:
        """
        Ø§ÛŒÙ† Ù…ØªØ¯ Ø¨Ø±Ø§ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ…-Ù…Ø­ÙˆØ± Ù…Ø¹Ù†Ø§ÛŒ Ø®Ø§ØµÛŒ Ù†Ø¯Ø§Ø±Ø¯.
        Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù…Ù‚Ø¯Ø§Ø± Ø«Ø§Ø¨Øª 0.0 Ø§Ù…Ù† Ùˆ ØµØ­ÛŒØ­ Ø§Ø³Øª.
        """
        return 0.0

    def compute_delta(self, split, metric_data):
        """
        Ø§ÛŒÙ† Ù…ØªØ¯ Ø¨Ù‡ Ø³Ø§Ø¯Ú¯ÛŒ ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø± Ø±Ø§ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù‡ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ Ø§Ø² ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø±ØŒ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ù…ØªÛŒØ§Ø² ØªÙ‚Ø³ÛŒÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        try:
            y = metric_data[:, 0] if metric_data.ndim > 1 else metric_data
            
            # Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙ‚Ø³ÛŒÙ…
            if split.dtype == bool:
                y_left, y_right = y[split], y[~split]
            else:
                mask = np.ones(len(y), dtype=bool)
                mask[split] = False
                y_left, y_right = y[split], y[mask]

            # Ø§Ú¯Ø± ÛŒÚ©ÛŒ Ø§Ø² ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯ØŒ ØªÙ‚Ø³ÛŒÙ… Ø¨ÛŒâ€ŒÙ…Ø¹Ù†Ø§Ø³Øª
            if len(y_left) == 0 or len(y_right) == 0:
                return 0.0

            # ğŸ”¥ ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø± ğŸ”¥
            # Ø¨Ù‡ Ø¬Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø³ØªÛŒ information gainØŒ Ø®ÙˆØ¯ ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø± (Ù…Ø«Ù„Ø§Ù‹ gain_ratio_criterion)
            # Ù…Ø³Ø¦ÙˆÙ„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø§Ø³Øª.
            return float(self.func(y_left, y_right))
        
        except Exception as e:
            # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ Ø¯Ø± ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø±ØŒ Ø§Ù…ØªÛŒØ§Ø² ØµÙØ± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            # print(f"[Debug] Error in criterion '{self.name}': {e}") # Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø®Ø· Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
            return 0.0


# ================================================================
# Ú©Ù„Ø§Ø³ Û²: WeightedVotingMetric (Ø¨Ø§ Ù…ØªØ¯ evaluate Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)
# Ø§ÛŒÙ† Ù…ØºØ² Ù…ØªÙÚ©Ø± Ù…Ø¯Ù„ Ø´Ù…Ø§Ø³Øª.
# ================================================================
class WeightedVotingMetric(MetricBase):
    """
    ÛŒÚ© Ù…ØªØ±ÛŒÚ© Ø³ÙØ§Ø±Ø´ÛŒ Ú©Ù‡ Ø§Ø² ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù†â€ŒØ¯Ø§Ø± Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªÙ‚Ø³ÛŒÙ…â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÙˆÛŒØ§ Ø¯Ø± Ù‡Ø± Ú¯Ø±Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‡Ø± Ù…Ø¹ÛŒØ§Ø± Ø¯Ø± Ú©Ø§Ù‡Ø´ False Negatives Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
    """
    def __init__(self, criteria, a):
        super().__init__()
        self.criteria = criteria  # Ù„ÛŒØ³ØªÛŒ Ø§Ø² (Ù†Ø§Ù…ØŒ ØªØ§Ø¨Ø¹) Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        self.a = a  # Ú©Ù„ Ø¯ÛŒØªØ§Ø³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (X)
        self.weights_dict = {}  # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù‡Ø± Ú¯Ø±Ù‡
        self._fn_cache = {}  # Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ FN

    def estimate_fn_for_criterion(self, name, x_data, y_node):
        """Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…Ø¹ÛŒØ§Ø± Ù…Ø´Ø®ØµØŒ Ø¨Ø§ Ø³Ø§Ø®ØªÙ† ÛŒÚ© Ø¯Ø±Ø®Øª Ù…ÙˆÙ‚ØªØŒ Ù…Ù‚Ø¯Ø§Ø± FN Ø±Ø§ ØªØ®Ù…ÛŒÙ† Ù…ÛŒâ€ŒØ²Ù†Ø¯."""
        from custom_tree_classifier.models.decision_tree import CustomDecisionTreeClassifier
        cache_key = f"{name}_{len(x_data)}_{hash(y_node.tobytes())}_{hash(x_data.tobytes())}"
        if cache_key in self._fn_cache:
            return self._fn_cache[cache_key]

        if x_data.shape[0] != y_node.shape[0]:
            return np.inf # Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø¯Ø§Ø¯Ù‡ØŒ ÛŒÚ© Ù¾Ù†Ø§Ù„ØªÛŒ Ø¨Ø²Ø±Ú¯ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…

        try:
            criterion_func = dict(self.criteria)[name]
            metric_obj = SingleCriterionMetric(name, criterion_func)
            
            model = CustomDecisionTreeClassifier(max_depth=10, metric=metric_obj)
            metric_data = y_node.reshape(-1, 1)
            model.fit(x_data, y_node, metric_data)
            
            probas = model.predict_proba(x_data)
            preds = (probas[:, 1] > 0.5).astype(int) if probas.shape[1] > 1 else np.zeros_like(y_node)
            
            fn_count = np.sum((y_node == 1) & (preds == 0))
            self._fn_cache[cache_key] = fn_count
            return fn_count
        except Exception as e:
            print(f"[ERROR] Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ FN Ø¨Ø±Ø§ÛŒ {name}: {e}")
            return np.inf

    # Ø¯Ø± Ú©Ù„Ø§Ø³ WeightedVotingMetric

    def update_weights_dynamic(self, x_data, y_node):
        """
        ğŸ”¥ Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Softmax ğŸ”¥
        FNÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú¯Ø±Ù‡ ÙØ¹Ù„ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        if len(x_data) < 2:
            return self.weights_dict 

        fn_values = np.array([self.estimate_fn_for_criterion(name, x_data, y_node) for name, _ in self.criteria], dtype=float)
        print(f"  FNs calculated: {dict(zip([c[0] for c in self.criteria], fn_values))}")

        # ===== Ø¨Ø®Ø´ Ú©Ù„ÛŒØ¯ÛŒ: Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ²Ù† Ø¨Ø§ Softmax =====

        # Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¯Ù…Ø§ (Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…)
        # Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø§Ø¹Ø« ØªÙˆØ²ÛŒØ¹ ÛŒÚ©Ù†ÙˆØ§Ø®Øªâ€ŒØªØ± ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        # Ù…Ù‚Ø¯Ø§Ø± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø¨Ø§Ø¹Ø« ØªÙ…Ø±Ú©Ø² Ø¨ÛŒØ´ØªØ± Ø±ÙˆÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        temperature = 1.0 

        # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨ÛŒâ€ŒÙ†Ù‡Ø§ÛŒØª Ø¯Ø± ØªØ§Ø¨Ø¹ Ù†Ù…Ø§ÛŒÛŒ (exp)ØŒ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§ Ø±Ø§ Ø´ÛŒÙØª Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ….
        # Ø§ÛŒÙ† ÛŒÚ© ØªÚ©Ù†ÛŒÚ© Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¹Ø¯Ø¯ÛŒ Softmax Ø§Ø³Øª Ùˆ Ø±ÙˆÛŒ Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ ØªØ£Ø«ÛŒØ±ÛŒ Ù†Ø¯Ø§Ø±Ø¯.
        scores = -fn_values  # FN Ú©Ù…ØªØ±ØŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ±
        scores -= np.max(scores) # Ø´ÛŒÙØª Ø¯Ø§Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Softmax
        exp_scores = np.exp(scores / temperature)
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø®Ø±Ø¬ ØµÙØ± Ù†Ø´ÙˆØ¯
        sum_exp_scores = np.sum(exp_scores)
        if sum_exp_scores > 1e-9:
            normalized_weights = exp_scores / sum_exp_scores
        else:
            # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§ Ø¨Ø³ÛŒØ§Ø± Ù…Ù†ÙÛŒ Ø¨Ø§Ø´Ù†Ø¯ØŒ ÙˆØ²Ù† Ù…Ø³Ø§ÙˆÛŒ Ø¨Ø¯Ù‡
            num_criteria = len(self.criteria)
            normalized_weights = np.full(num_criteria, 1.0 / num_criteria)
        
        # ============================================
        
        self.weights_dict = {name: weight for (name, _), weight in zip(self.criteria, normalized_weights)}
        print(f"  New weights set (using Softmax): {self.weights_dict}")
        return self.weights_dict



# ================================================================
# ğŸ”¥ Ø¨Ù„ÙˆÚ© Ù†Ù‡Ø§ÛŒÛŒ Ú©Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³ WeightedVotingMetric ğŸ”¥
# ================================================================

    def evaluate(self, y_left, y_right, split_info=None):
        """
        Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ: Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ ÛŒÚ© ØªÙ‚Ø³ÛŒÙ… Ø±Ø§ Ø¨Ø§ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ (Min-Max) Ùˆ Ø³Ù¾Ø³
        Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒØŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        if len(y_left) == 0 or len(y_right) == 0:
            return 0.0

        # Ø§Ú¯Ø± Ø¨Ù‡ Ù‡Ø± Ø¯Ù„ÛŒÙ„ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯ØŒ Ø§Ø² ÙˆØ²Ù† Ù…Ø³Ø§ÙˆÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if not self.weights_dict:
            print("[WARNING] `evaluate` ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´Ø¯ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯Ù†Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ²Ù† Ù…Ø³Ø§ÙˆÛŒ.")
            self.weights_dict = {name: 1.0 / len(self.criteria) for name, _ in self.criteria}
        
        # Û±. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø®Ø§Ù… Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¹ÛŒØ§Ø± Ø¨Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ØªØ§Ø¨Ø¹ Ø¢Ù†
        raw_scores = []
        for name, func in self.criteria:
            try:
                # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· Ø®ÙˆØ¯ ØªØ§Ø¨Ø¹ Ù…Ø¹ÛŒØ§Ø±
                raw_scores.append(float(func(y_left, y_right)))
            except Exception:
                raw_scores.append(0.0)

        # Û². Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ [0, 1] Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ø§Ø¯Ù„Ø§Ù†Ù‡ (Min-Max Scaling)
        scores_np = np.array(raw_scores)
        min_score, max_score = np.min(scores_np), np.max(scores_np)
        
        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ± Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª ÛŒÚ©Ø³Ø§Ù† Ø¨Ø§Ø´Ù†Ø¯
        if (max_score - min_score) > 1e-9:
            normalized_scores = (scores_np - min_score) / (max_score - min_score)
        else:
            # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª ÛŒÚ©Ø³Ø§Ù† Ø¨ÙˆØ¯Ù†Ø¯ØŒ Ù‡Ù…Ù‡ Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ø´Ø¯Ù‡â€ŒÙ‡Ø§ 0.5 Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
            normalized_scores = np.full_like(scores_np, 0.5)

        # Û³. Ø®ÙˆØ§Ù†Ø¯Ù† ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡
        weights = np.array([self.weights_dict.get(name, 0.0) for name, _ in self.criteria])

        # Û´. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ø´Ø¯Ù‡
        if weights.sum() > 0:
            # np.dot Ø­Ø§ØµÙ„Ø¶Ø±Ø¨ Ø¯Ø§Ø®Ù„ÛŒ Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø± Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ø§Ù† Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ø§Ø³Øª
            weighted_score = np.dot(normalized_scores, weights)
        else:
            weighted_score = np.mean(normalized_scores) if len(normalized_scores) > 0 else 0.0
            
        return float(weighted_score)


    def compute_metric(self, metric_data: np.ndarray) -> float:
        """
        Ø§ÛŒÙ† Ù…ØªØ¯ Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¬Ø¯ÛŒØ¯ØŒ Ø¯ÛŒÚ¯Ø± Ú©Ø§Ø±Ø¨Ø±Ø¯ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
        Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ú©Ù„ÛŒØŒ ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
        """
        # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯ ÛŒØ§ ÛŒÚ© Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯.
        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ØµÙØ± Ø§Ù…Ù†â€ŒØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡ Ø§Ø³Øª.
        return 0.0


    def compute_delta(self, split: np.ndarray, metric_data: np.ndarray) -> float:
        """
        Ø§ÛŒÙ† Ù…ØªØ¯ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ÙˆØ¸ÛŒÙÙ‡ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ø§Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ `evaluate` Ø±Ø§
        Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        y = metric_data[:, 0] if metric_data.ndim > 1 else metric_data
        
        if split.dtype == bool:
            y_left, y_right = y[split], y[~split]
        else:
            mask = np.ones(len(y), dtype=bool)
            mask[split] = False
            y_left, y_right = y[split], y[mask]
            
        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ØªØ¯ evaluate Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
        return self.evaluate(y_left, y_right)



# ================================================================
# Ú©Ù„Ø§Ø³ Û³: CriterionWrapper (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# ================================================================
class CriterionWrapper:
    # Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø§Ú¯Ø± Ø¯Ø± Ø¬Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø°Ù Ø´ÙˆØ¯.
    # Ø¯Ø± Ø§ÛŒÙ† Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¬Ø¯ÛŒØ¯ØŒ Ù†Ù‚Ø´ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ù†Ø¯Ø§Ø±Ø¯.
    def __init__(self, name, func):
        self.name = name
        self.func = func
        
    def calculate_score(self, y_left, y_right):
        try:
            return self.func(y_left, y_right)
        except Exception:
            return 0.0

# ================================================================
# Ú©Ù„Ø§Ø³ Û´: WeightedDecisionTreeModel (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø§Ø±Ú©Ø³ØªØ±Ø§ØªÙˆØ± Ø§ØµÙ„ÛŒ Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ØªØºÛŒÛŒØ± Ù†Ø¯Ø§Ø±Ø¯.
# ================================================================
class WeightedDecisionTreeModel:
# Ø¯Ø± ÙØ§ÛŒÙ„ src/model/weighted_decision_tree.py
# Ø¯Ø± Ú©Ù„Ø§Ø³ WeightedDecisionTreeModel

    def __init__(self, criteria_funcs_weights=None, positive_label=1, max_depth=5, a=None):
        if criteria_funcs_weights is None:
            criteria_funcs_weights = [
                #("gini", gini_criterion), ("gain_ratio", gain_ratio_criterion),
                ("twoing", twoing_criterion), ("normalized_gain", normalized_gain_criterion),
                ("multi_class_hellinger", multi_class_hellinger), ("marshall", marsh_criterion),
                ("g_statistic", g_statistic_criterion), ("dkm", dkm_criterion),
                ("chi_squared", chi_squared_criterion), ("bhattacharyya", bhattacharyya_criterion),
                ("kolmogorov_smirnov", kolmogorov_smirnov_criterion),
            ]
        self.criteria = criteria_funcs_weights
        self.positive_label = positive_label
        
        # ğŸ”¥ Ø®Ø· Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ùˆ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ú©Ù‡ ÙØ±Ø§Ù…ÙˆØ´ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯
        self.max_depth = max_depth
        
        if a is None:
            raise ValueError("a Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±Ø§ Ø¨Ù‡ Ù…Ø¯Ù„ Ø¨Ø¯Ù‡ÛŒØ¯.")
        
        self.a = np.array(a.values) if hasattr(a, "values") else np.array(a)
        
        self.metric = WeightedVotingMetric(self.criteria, self.a)
        self.model = None


    def compute_initial_weights(self, X, y):
        from custom_tree_classifier.models.decision_tree import CustomDecisionTreeClassifier

        """ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú¯Ø±Ù‡ Ø±ÛŒØ´Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
        print("[INIT] Ø´Ø±ÙˆØ¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú¯Ø±Ù‡ Ø±ÛŒØ´Ù‡...")
        # Ø§Ø² Ù‡Ù…Ø§Ù† Ù…Ù†Ø·Ù‚ `update_weights_dynamic` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        initial_weights = self.metric.update_weights_dynamic(X, y)
        self.metric.weights_dict = initial_weights
        print(f"ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {initial_weights}")

    # Ø¯Ø± Ú©Ù„Ø§Ø³ WeightedDecisionTreeModel
    
# Ø¯Ø± ÙØ§ÛŒÙ„ src/model/weighted_decision_tree.py

    def fit(self, x, y):
        """
        Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
        """
        # ğŸ”¥ Ø§ØµÙ„Ø§Ø­ÛŒÙ‡ Û±: Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ú©Ø³ØªÙ† Ú†Ø±Ø®Ù‡ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ
        from custom_tree_classifier.models.decision_tree import CustomDecisionTreeClassifier

        # ğŸ”¥ Ø§ØµÙ„Ø§Ø­ÛŒÙ‡ Û² (Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…): Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ø¯Ø± Ù„Ø­Ø¸Ù‡ Ù†ÛŒØ§Ø²
        # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯Ù‡ (None Ø§Ø³Øª)ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø³Ø§Ø²
        if self.model is None:
            # Ø¯Ø± Ù…ØªØ¯ __init__ Ú©Ù„Ø§Ø³ WeightedDecisionTreeModel
            #self.model = CustomDecisionTreeClassifier() # Ø¯Ø±Ø³Øª: ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ú©Ù„Ø§Ø³ Ø³Ø§Ø®ØªÙ‡â€ŒØ§ÛŒØ¯

            self.model = CustomDecisionTreeClassifier(
                max_depth=self.max_depth,
                metric=self.metric
            )
        
        # Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
        X_fit = x.values if hasattr(x, "values") else x
        y_fit = y.values if hasattr(y, "values") else y
        
        print(f"Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ - Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡: x={X_fit.shape}, y={y_fit.shape}")
        
        # Ù…Ø±Ø­Ù„Ù‡ Û²: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ ØªÙ†Ø¸ÛŒÙ… ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
        self.compute_initial_weights(X_fit, y_fit)
        
        # Ù…Ø±Ø­Ù„Ù‡ Û³: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù…ØªØ±ÛŒÚ© (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
        metric_data = y_fit.reshape(-1, 1)

 

        import custom_tree_classifier.models.decision_tree as dt

        print("Path of the loaded module:", dt.__file__)


        # Ù…Ø±Ø­Ù„Ù‡ Û´: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ fit Ø§ØµÙ„ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ (Ø­Ø§Ù„Ø§ Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        self.model.fit(X_fit, y_fit, metric_data)



        print("Ø¢Ù…ÙˆØ²Ø´ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")


    def predict(self, x):
        X_pred = x.values if hasattr(x, "values") else x
        probas = self.model.predict_proba(X_pred)
        if probas.shape[1] > 1:
            return np.argmax(probas, axis=1)
        else:
            return (probas[:, 0] > 0.5).astype(int)

    def predict_proba(self, x):
        X_pred = x.values if hasattr(x, "values") else x
        return self.model.predict_proba(X_pred)

# ================================================================
# Ø¨Ø®Ø´ Ø§Ø¬Ø±Ø§ÛŒÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# ================================================================
if __name__ == "__main__":
    from sklearn.datasets import make_classification
    
    # Ø³Ø§Ø®Øª Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡
    X_data, y_data = make_classification(n_samples=100, n_features=10, n_informative=5, n_redundant=0, n_classes=2, random_state=42)
    
    # Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    model = WeightedDecisionTreeModel(a=X_data, max_depth=5)
    model.fit(X_data, y_data)
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    predictions = model.predict(X_data)
    probabilities = model.predict_proba(X_data)
    
    print("\n--- Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ ---")
    print(f"ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§: {len(predictions)}")
    print(f"Ù†Ù…ÙˆÙ†Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§: {predictions[:10]}")
    print(f"Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: \n{probabilities[:5]}")
    print("\nÙ…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯!")
